# ğŸ§ª Testare RapidÄƒ - AI Chat

## âœ… Checklist Pre-testare

Ãnainte de a testa funcÈ›ia de chat, asigurÄƒ-te cÄƒ ai:

- [x] Ollama instalat pe sistem
- [ ] Model AI descÄƒrcat (llama2 recomandat)
- [ ] Server Ollama pornit
- [ ] AplicaÈ›ie React pornitÄƒ

## ğŸš€ PaÈ™i pentru Testare

### 1. VerificÄƒ instalarea Ollama

```powershell
ollama --version
```

**Output aÈ™teptat:**
```
ollama version is 0.x.x
```

### 2. DescarcÄƒ modelul (dacÄƒ nu e deja)

```powershell
ollama pull llama2
```

**Output aÈ™teptat:**
```
pulling manifest
pulling xxx... 100%
...
success
```

â±ï¸ **Timp estimat:** 3-5 minute (depinde de internet)

### 3. PorneÈ™te serverul Ollama

**OpÈ›iunea A - Script automat:**
```powershell
.\start-ollama.ps1
```

**OpÈ›iunea B - Manual:**
```powershell
ollama serve
```

**Output aÈ™teptat:**
```
Listening on 127.0.0.1:11434 (version 0.x.x)
```

âš ï¸ **IMPORTANT:** LasÄƒ acest terminal deschis!

### 4. PorneÈ™te aplicaÈ›ia (Ã®ntr-un alt terminal)

```powershell
npm run dev
```

**Output aÈ™teptat:**
```
VITE v5.x.x  ready in xxx ms

âœ  Local:   http://localhost:5173/
```

### 5. TesteazÄƒ API-ul Ollama (opÈ›ional)

Ãntr-un al treilea terminal:

```powershell
$body = @{
    model = "llama2"
    prompt = "Salut!"
    stream = $false
} | ConvertTo-Json

Invoke-RestMethod -Uri "http://localhost:11434/api/generate" -Method POST -Body $body -ContentType "application/json"
```

**Output aÈ™teptat:** Obiect JSON cu rÄƒspuns AI

### 6. AcceseazÄƒ aplicaÈ›ia

1. Deschide browser la: `http://localhost:5173`
2. AutentificÄƒ-te (dacÄƒ nu eÈ™ti deja)
3. Click pe butonul **"ÃntreabÄƒ AI-ul"** din pagina principalÄƒ

SAU

AcceseazÄƒ direct: `http://localhost:5173/ai-chat`

## ğŸ§ª Teste de FuncÈ›ionalitate

### Test 1: Mesaj Basic
1. Scrie Ã®n chat: `Salut!`
2. ApasÄƒ Enter sau click pe butonul Send
3. âœ… **AÈ™teptat:** RÄƒspuns de la AI Ã®n 2-5 secunde

### Test 2: Ãntrebare SugeratÄƒ
1. Click pe una din Ã®ntrebÄƒrile sugerate de jos
2. Click pe Send
3. âœ… **AÈ™teptat:** RÄƒspuns detaliat despre subiect

### Test 3: Ãntrebare ComplexÄƒ
```
Care sunt cele mai eficiente metode de reducere a amprentei de carbon pentru o familie obiÈ™nuitÄƒ?
```
âœ… **AÈ™teptat:** RÄƒspuns structurat cu recomandÄƒri

### Test 4: ConversaÈ›ie Multi-turn
1. Ãntrebare: `Ce este energia regenerabilÄƒ?`
2. RÄƒspuns AI...
3. Follow-up: `PoÈ›i sÄƒ-mi dai exemple concrete?`
4. âœ… **AÈ™teptat:** AI rÄƒspunde Ã®n context

### Test 5: È˜terge Chat
1. Click pe butonul "È˜terge Chat"
2. âœ… **AÈ™teptat:** ConversaÈ›ia se reseteazÄƒ la mesajul iniÈ›ial

### Test 6: Responsive
1. RedimensioneazÄƒ fereastra browser
2. âœ… **AÈ™teptat:** UI-ul se adapteazÄƒ (butoane, mesaje)

## ğŸ› Troubleshooting Rapid

### Eroare: "Eroare la comunicarea cu Ollama"

**CauzÄƒ:** Server Ollama nu ruleazÄƒ

**Fix rapid:**
```powershell
# Terminal nou
ollama serve
```

---

### Eroare: "model 'llama2' not found"

**CauzÄƒ:** Model nedescarcat

**Fix rapid:**
```powershell
ollama pull llama2
```

---

### Mesaje foarte lente (>30 secunde)

**CauzÄƒ:** System resources sau model prea mare

**Fix rapid:** FoloseÈ™te model mai mic
```powershell
ollama pull mistral
```

Apoi Ã®n `src/pages/AiChat.tsx`, linia 81:
```typescript
model: 'mistral',  // Ã®n loc de 'llama2'
```

---

### Port 11434 deja folosit

**CauzÄƒ:** AltÄƒ instanÈ›Äƒ Ollama ruleazÄƒ

**Fix rapid:**
```powershell
# GÄƒseÈ™te procesul
netstat -ano | findstr :11434

# OpreÈ™te procesul (Ã®nlocuieÈ™te <PID> cu numÄƒrul din output)
taskkill /PID <PID> /F

# PorneÈ™te din nou
ollama serve
```

---

### Chat nu se Ã®ncarcÄƒ / ecran alb

**CauzÄƒ:** Eroare JavaScript

**Fix rapid:**
1. Deschide Console (F12)
2. VerificÄƒ erorile
3. ReÃ®mprospÄƒteazÄƒ pagina (Ctrl+F5)

---

### Mesajele nu se scroll-eazÄƒ automat

**CauzÄƒ:** Bug UI minor

**Fix rapid:** Scroll manual sau reÃ®mprospÄƒteazÄƒ pagina

## ğŸ“Š Verificare PerformanÈ›Äƒ

### Timp de rÄƒspuns aÈ™teptat:

| Model | Hardware | Timp RÄƒspuns |
|-------|----------|--------------|
| llama2 | CPU | 10-30s |
| llama2 | GPU | 2-5s |
| mistral | CPU | 5-15s |
| mistral | GPU | 1-3s |

### Utilizare resurse:

- **RAM:** 4-8GB Ã®n timpul rulÄƒrii
- **CPU:** 50-100% Ã®n timpul generÄƒrii
- **Disk:** ~4GB pentru model

## ğŸ¯ Criterii de Succes

FuncÈ›ia este operaÈ›ionalÄƒ dacÄƒ:

- [x] âœ… Serverul Ollama porneÈ™te fÄƒrÄƒ erori
- [x] âœ… Pagina /ai-chat se Ã®ncarcÄƒ
- [x] âœ… PoÈ›i trimite mesaje
- [x] âœ… PrimeÈ™ti rÄƒspunsuri de la AI
- [x] âœ… Istoricul conversaÈ›iei se pÄƒstreazÄƒ
- [x] âœ… Butoanele funcÈ›ioneazÄƒ (Send, È˜terge)
- [x] âœ… Nu apar erori Ã®n Console

## ğŸ“¸ Screenshot-uri AÈ™teptate

### 1. Pagina Chat (IniÈ›ial)
- Header cu "Asistent AI Eco ğŸ¤–"
- Mesaj de bun venit de la AI
- Input gol
- 4 Ã®ntrebÄƒri sugerate

### 2. DupÄƒ Primul Mesaj
- Mesaj utilizator (dreapta, albastru)
- Indicator "Se gÃ¢ndeÈ™te..."
- (apoi) RÄƒspuns AI (stÃ¢nga, gri)

### 3. ConversaÈ›ie ActivÄƒ
- Multiple mesaje user + AI
- Timestamp-uri
- Scroll bar (dacÄƒ >5 mesaje)

## ğŸ”„ Reset Complet (dacÄƒ totul dÄƒ greÈ™)

```powershell
# 1. OpreÈ™te tot
# Ctrl+C Ã®n terminalele cu Ollama È™i Vite

# 2. È˜terge modelul È™i re-descarcÄƒ
ollama rm llama2
ollama pull llama2

# 3. Re-porneÈ™te serverul
ollama serve

# 4. (alt terminal) Re-porneÈ™te aplicaÈ›ia
npm run dev

# 5. AceseazÄƒ /ai-chat Ã®n browser nou (incognito)
```

## ğŸ“ Support

DacÄƒ Ã®ntÃ¢mpini probleme:

1. VerificÄƒ toate punctele din checklist
2. CiteÈ™te secÈ›iunea Troubleshooting
3. VerificÄƒ logs Ã®n terminal (ambele)
4. VerificÄƒ Console Ã®n browser (F12)

## ğŸ‰ Test Final

ÃntreabÄƒ AI-ul:
```
ExplicÄƒ-mi Ã®n 3 propoziÈ›ii ce Ã®nseamnÄƒ sustenabilitate.
```

DacÄƒ primeÈ™ti un rÄƒspuns coerent Ã®n romÃ¢nÄƒ despre sustenabilitate, **totul funcÈ›ioneazÄƒ perfect!** ğŸŠ

---

**Happy Testing! ğŸ§ªğŸ¤–ğŸŒ±**
